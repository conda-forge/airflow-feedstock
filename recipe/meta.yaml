{% set name = "airflow" %}
{% set pypi_name = "apache-airflow" %}
{% set version = "3.1.3" %}
# python must be less than this version (also update in skip below)
{% set python_over = "3.14" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ pypi_name[0] }}/{{ pypi_name }}/apache_airflow-{{ version }}.tar.gz
  sha256: 8dd5979cb93c6d522359b661276b8b6293dfebaca74267f753986dbdca1ba72d

build:
  noarch: python
  number: 0

requirements:
  host:
    - python {{ python_min }}

outputs:
  - name: {{ name }}
    script: install_airflow.sh
    build:
      noarch: python
    requirements:
      host:
        - python {{ python_min }}
        - gitpython ==3.1.45
        - gitdb ==4.0.12
        - hatchling ==1.27.0
        - packaging ==25.0
        - pathspec ==0.12.1
        - pluggy ==1.5.0
        - smmap ==5.0.2
        # for all python (not just py < 3.11) so we can stay noarch: python
        - tomli ==2.2.1
        - trove-classifiers ==2025.9.11.17
        - pip
      run:
        - python >={{ python_min }},<{{ python_over }}
        - apache-airflow-task-sdk >=1.1.1
        - apache-airflow-core =={{ version }}
        # temporary constriant to avoid error fixed in
        # https://github.com/apache/airflow/pull/57335
        - structlog >=25.2.0,<25.5.0

    test:
      commands:
        - pip check
        - airflow --help
        - airflow db --help
        - airflow db check
      imports:
        - airflow

      requires:
        - python {{ python_min }}
        - pip

  # alternative name for the package
  - name: apache-airflow
    build:
      noarch: python
    requirements:
      host:
        # needed to make sure each python version gets a unique build string
        - python {{ python_min }}
      run:
        - python >={{ python_min }},<{{ python_over }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-all-core
    build:
      noarch: python
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }},<{{ python_over }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - apache-airflow-core-with-all
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-all
    build:
      noarch: python
    requirements:
      host:
        - python {{ python_min }}
      run:
        # Some packages require pandas >=2.2.3 and others require older.
        # Since we can't have it both ways, we're leaving out packages
        # requiring the older pandas for now.
        #
        - python >={{ python_min }},<{{ python_over }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - apache-airflow-providers-amazon-with-aiobotocore >=9.6.0
        - apache-airflow-providers-amazon-with-s3fs
        - apache-airflow-providers-common-sql-with-pandas
        - apache-airflow-providers-common-sql-with-polars
        - apache-airflow-core-with-async
        - apache-airflow-core-with-graphviz
        - apache-airflow-core-with-kerberos
        - apache-airflow-core-with-otel
        - apache-airflow-core-with-sentry
        - apache-airflow-core-with-statsd
        - apache-airflow-core-with-all
        - apache-airflow-providers-airbyte >=5.0.0
        - apache-airflow-providers-alibaba >=3.0.0
        - apache-airflow-providers-amazon >=9.0.0
        # doesn't work with pandas >=2.2.3
        # - apache-airflow-providers-apache-beam >=5.8.1
        - apache-airflow-providers-apache-cassandra >=3.7.0
        - apache-airflow-providers-apache-drill >=2.8.1
        - apache-airflow-providers-apache-druid >=3.12.0
        - apache-airflow-providers-apache-flink >=1.6.0
        - apache-airflow-providers-apache-hdfs >=4.6.0
        - apache-airflow-providers-apache-hive >=8.2.1
        - apache-airflow-providers-apache-iceberg >=1.2.0
        - apache-airflow-providers-apache-impala >=1.5.2
        - apache-airflow-providers-apache-kafka >=1.6.1
        - apache-airflow-providers-apache-kylin >=3.8.0
        - apache-airflow-providers-apache-livy >=3.9.2
        - apache-airflow-providers-apache-pig >=4.6.0
        - apache-airflow-providers-apache-pinot >=4.5.1
        - apache-airflow-providers-apache-spark >=4.11.1
        # not on conda-forge
        # - apache-airflow-providers-apache-tinkerpop >=1.0.0
        - apache-airflow-providers-apprise >=1.4.1
        - apache-airflow-providers-arangodb >=2.7.0
        - apache-airflow-providers-asana >=2.7.0
        - apache-airflow-providers-atlassian-jira >=2.7.1
        - apache-airflow-providers-celery >=3.8.3
        - apache-airflow-providers-cloudant >=4.0.1
        - apache-airflow-providers-cncf-kubernetes >=9.0.0
        # not on conda-forge
        # - apache-airflow-providers-cohere >=1.4.0
        - apache-airflow-providers-common-compat >=1.2.1
        - apache-airflow-providers-common-io >=1.4.2
        - apache-airflow-providers-common-messaging >=2.0.0
        - apache-airflow-providers-common-sql >=1.18.0
        - apache-airflow-providers-databricks >=6.11.0
        - apache-airflow-providers-datadog >=3.8.0
        - apache-airflow-providers-dbt-cloud >=3.11.0
        - apache-airflow-providers-dingding >=3.7.0
        - apache-airflow-providers-discord >=3.9.0
        - apache-airflow-providers-docker >=3.14.1
        - apache-airflow-providers-edge3 >=1.0.0
        - apache-airflow-providers-elasticsearch >=5.5.2
        - apache-airflow-providers-exasol >=4.6.1
        # temporary constraint because of bad dependency
        - pyexasol !=1.1.1
        # doesn't work with pandas >=2.2.3
        # - apache-airflow-providers-fab >=2.2.0
        - apache-airflow-providers-facebook >=3.7.0
        - apache-airflow-providers-ftp >=3.12.0
        - apache-airflow-providers-git >=0.0.2
        - apache-airflow-providers-github >=2.8.0
        - apache-airflow-providers-google >=10.24.0
        - apache-airflow-providers-grpc >=3.7.0
        - apache-airflow-providers-hashicorp >=4.0.0
        - apache-airflow-providers-http >=4.13.2
        - apache-airflow-providers-imap >=3.8.0
        - apache-airflow-providers-influxdb >=2.8.0
        - apache-airflow-providers-jdbc >=4.5.2
        - apache-airflow-providers-jenkins >=3.7.2
        # not available on conda-forge
        # - apache-airflow-providers-keycloak >=0.0.1
        - apache-airflow-providers-microsoft-azure >=10.5.1
        - apache-airflow-providers-microsoft-mssql >=3.9.2
        - apache-airflow-providers-microsoft-psrp >=3.0.0
        - apache-airflow-providers-microsoft-winrm >=3.6.1
        - apache-airflow-providers-mongo >=4.2.2
        - apache-airflow-providers-mysql >=5.7.2
        - apache-airflow-providers-neo4j >=3.8.0
        - apache-airflow-providers-odbc >=4.8.0
        - apache-airflow-providers-openai >=1.5.0
        - apache-airflow-providers-openfaas >=3.7.0
        - apache-airflow-providers-openlineage >=2.3.0
        - apache-airflow-providers-opensearch >=1.5.0
        - apache-airflow-providers-opsgenie >=5.8.0
        - apache-airflow-providers-oracle >=3.12.0
        - apache-airflow-providers-pagerduty >=3.8.1
        - apache-airflow-providers-papermill >=3.8.2
        - apache-airflow-providers-pgvector >=1.4.0
        - apache-airflow-providers-pinecone >=2.1.1
        - apache-airflow-providers-postgres >=5.13.1
        - apache-airflow-providers-presto >=5.7.0
        - apache-airflow-providers-qdrant >=1.3.0
        - apache-airflow-providers-redis >=4.0.0
        - apache-airflow-providers-salesforce >=5.9.0
        - apache-airflow-providers-samba >=4.9.0
        - apache-airflow-providers-segment >=3.7.0
        - apache-airflow-providers-sendgrid >=4.0.0
        - apache-airflow-providers-sftp >=5.0.0
        - apache-airflow-providers-singularity >=3.7.0
        - apache-airflow-providers-slack >=8.9.1
        - apache-airflow-providers-smtp >=1.8.1
        - apache-airflow-providers-snowflake >=5.8.0
        - apache-airflow-providers-sqlite >=3.9.1
        - apache-airflow-providers-ssh >=3.14.0
        - apache-airflow-providers-standard >=0.0.1
        - apache-airflow-providers-tableau >=5.0.0
        - apache-airflow-providers-telegram >=4.7.0
        # not on conda-forge
        # - apache-airflow-providers-teradata >=2.6.1
        - apache-airflow-providers-trino >=5.8.1
        - apache-airflow-providers-vertica >=3.9.1
        - apache-airflow-providers-weaviate >=3.0.0
        - apache-airflow-providers-yandex >=4.0.0
        - apache-airflow-providers-ydb >=1.4.0
        - apache-airflow-providers-zendesk >=4.9.0
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

about:
  home: http://airflow.apache.org
  license: Apache-2.0
  license_file: LICENSE
  summary: |
    Airflow is a platform to programmatically author, schedule and monitor
    workflows

  description: |
    Use airflow to author workflows as directed acyclic graphs (DAGs)
    of tasks. The airflow scheduler executes your tasks on an array of
    workers while following the specified dependencies. Rich command
    line utilities make performing complex surgeries on DAGs a snap.
    The rich user interface makes it easy to visualize pipelines
    running in production, monitor progress, and troubleshoot issues
    when needed.

    When workflows are defined as code, they become more maintainable,
    versionable, testable, and collaborative.

  doc_url: http://pythonhosted.org/airflow/profiling.html
  dev_url: https://github.com/apache/airflow

extra:
  recipe-maintainers:
    - sodre
    - halldc
    - xylar
