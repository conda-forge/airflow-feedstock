{% set name = "airflow" %}
{% set version = "2.2.0" %}
{% set sha256 = "f53d7fafec8ffe7ce87b39be7842adca67b1215f841a2390dd2e5d17b4a0161d" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  fn: {{ name }}-{{ version }}.tar.gz
  url: https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz
  sha256: {{ sha256 }}
  patches:
    # OSX uses md5 -r instead of md5sum
    - 0001-osx-fix-md5.patch  # [osx]

build:
  skip: true  # [win]
  number: 0

outputs:
  - name: {{ name }}
    script: install_airflow.sh
    build:
      entry_points:
        - airflow=airflow.__main__:main
    requirements:
      host:
        - python
        - pip
        - gitpython <3.1.22  # [py<37]
        - gitpython  # [py>=37]
        - docutils
        - yarn
      run:
        - python
        - alembic >=1.2,<2.0
        - argcomplete >=1.10,<2.0
        - attrs >=20.0,<21.0
        - blinker
        - cached-property >=1.5,<2.0  # [py<=37]
        - cattrs >=1.0,<1.1.0  # [py<=36]
        - cattrs >=1.1,<1.7.0  # [py>36]
        - clickclick >=1.2
        - colorlog >=4.0.2,<6.0
        - croniter >=0.3.17,<1.1
        - cryptography >=0.9.3
        - dataclasses  # [py<37]
        - dill >=0.2.2,<0.4
        - docutils <0.17
        - flask >=1.1.0,<2.0
        - flask-appbuilder >=3.3.2,<4.0.0
        - flask-caching >=1.5.0,<2.0.0
        - flask-login >=0.3,<0.5
        - flask-wtf >=0.14.3,<0.15
        - python-graphviz >=0.12
        - gunicorn >=19.5.0
        - httpx
        - importlib_metadata >=1.7  # [py<39]
        - inflection >=0.3.1
        - iso8601 >=0.1.12
        - itsdangerous >=1.1.0,<2.0
        - jinja2 >=2.10.1,<4
        - jsonschema >=3.0,<4.0
        - lazy-object-proxy
        - lockfile >=0.12.2
        - markdown >=2.5.2,<4.0
        - markupsafe >=1.1.1,<2.0
        - marshmallow-oneofschema >=2.0.1
        - openapi-spec-validator >=0.2.4
        - pendulum >=2.0,<3.0
        - pep562 >=1.0,<2.0  # [py<37]
        - psutil >=4.2.0,<6.0.0
        - pygments >=2.0.1,<3.0
        - pyjwt <2
        - python-daemon >=2.2.4
        - python-dateutil >=2.3,<3
        - python-nvd3 >=0.15.0,<0.16.0
        - python-slugify >=3.0.0,<5.0
        - python3-openid >=3.2,<4.0
        - pyyaml >=5.1
        - rich >=9.2.0
        - setproctitle >=1.1.8,<2
        - sqlalchemy >=1.3.18
        - sqlalchemy-jsonfield >=1.0,<2.0
        - swagger-ui-bundle >=0.0.2
        - tabulate >=0.7.5,<0.9
        - tenacity >=6.2.0
        - termcolor >=1.1.0
        - typing-extensions >=3.7.4  # [py<38]
        - unicodecsv >=0.14.1
        - werkzeug >=1.0.1,<2.0
        - apache-airflow-providers-ftp
        - apache-airflow-providers-http
        - apache-airflow-providers-imap
        - apache-airflow-providers-sqlite

    test:
      commands:
        - pip check
        - airflow --help
        - airflow db init
      imports:
        - airflow
        - airflow.api
        - airflow.api.auth
        - airflow.api.auth.backend
        - airflow.api.client
        - airflow.api.common
        - airflow.api.common.experimental
        - airflow.api_connexion
        - airflow.cli
        - airflow.cli.commands
        - airflow.config_templates
        - airflow.contrib
        - airflow.contrib.hooks
        - airflow.contrib.operators
        - airflow.contrib.secrets
        - airflow.contrib.sensors
        - airflow.contrib.task_runner
        - airflow.contrib.utils
        - airflow.example_dags
        - airflow.example_dags.subdags
        - airflow.executors
        - airflow.hooks
        - airflow.jobs
        - airflow.kubernetes
        - airflow.lineage
        - airflow.macros
        - airflow.migrations
        - airflow.migrations.versions
        - airflow.models
        - airflow.mypy
        - airflow.mypy.plugin
        - airflow.operators
        - airflow.secrets
        - airflow.security
        - airflow.sensors
        - airflow.serialization
        - airflow.smart_sensor_dags
        - airflow.task
        - airflow.task.task_runner
        - airflow.ti_deps
        - airflow.ti_deps.deps
        - airflow.utils
        - airflow.utils.log
        - airflow.www
        - airflow.www.api
        - airflow.www.api.experimental
      requires:
        - pip

  # alternative name for the core package
  - name: apache-airflow
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-apache-atlas
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - atlasclient >=0.1.2
    test:
      imports:
        - airflow.lineage
        - airflow.lineage.entities
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-apache-beam
    build:
      # apache-beam doesn't support py39 yet
      skip: true  # [py>=39]
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - apache-beam >=2.20.0
    test:
      imports:
        - airflow
        - apache_beam
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-apache-webhdfs
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-hdfs >=2.0.4
        - apache-airflow-providers-apache-hdfs
    test:
      imports:
        - airflow
        - hdfs
        - airflow.hooks.webhdfs_hook
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-async
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - dnspython <2.0.0
        - eventlet >=0.9.7
        - gevent >=0.13
        - greenlet >=0.4.9
    test:
      imports:
        - airflow
        - eventlet
        - gevent
        - greenlet
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-cgroups
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cgroupspy >=0.1.4
    test:
      imports:
        - airflow
        - cgroupspy
        - airflow.contrib.task_runner.cgroup_task_runner
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-dask
    build:
      # distributed<2.20 was not built for py39
      skip: true  # [py>=39]
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cloudpickle >=1.4.1,<1.5.0
        # dask 2021.6.1 does not work with `distributed`
        - dask >=2.9.0,<2021.6.1
        - distributed >=2.11.1,<2.20
    test:
      imports:
        - airflow
        - distributed
        - airflow.executors.dask_executor
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-github_enterprise
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - authlib
    test:
      imports:
        - airflow
        - authlib
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-google_auth
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - authlib
    test:
      imports:
        - airflow
        - authlib
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-kerberos
    build:
      # thrift_sasl has not yet been built for py39
      skip: true  # [py>=39]
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pykerberos >=1.1.13
        - requests-kerberos >=0.10.0
        - thrift_sasl >=0.2.0
    test:
      imports:
        - airflow
        - kerberos
        - airflow.api.auth.backend.kerberos_auth
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-ldap
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - ldap3 >=2.5.1
        - python-ldap
    test:
      imports:
        - airflow
        - ldap3
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-leveldb
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - plyvel
    test:
      imports:
        - airflow
        - plyvel
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-pandas
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pandas >=0.17.1,<2.0
    test:
      imports:
        - airflow
        - pandas
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-password
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - bcrypt >=2.0.0
        - flask-bcrypt >=0.7.1
    test:
      imports:
        - airflow
        - flask_bcrypt
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-rabbitmq
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - amqp
    test:
      imports:
        - airflow
        - amqp
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-sentry
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - blinker >=1.1
        - sentry-sdk >=0.8.0
    test:
      imports:
        - airflow
        - sentry_sdk
        - airflow.sentry
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-statsd
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - statsd >=3.3.0,<4.0
    test:
      imports:
        - airflow
        - statsd
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-tableau
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - tableauserverclient >=0.12,<1.0
    test:
      imports:
        - airflow
        - tableauserverclient
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-virtualenv
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - virtualenv
    test:
      imports:
        - airflow
        - virtualenv
      commands:
        - pip check
      requires:
        - pip

  # deprecated aliases
  - name: {{ name }}-with-atlas
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage('airflow-with-apache-atlas', max_pin='x.x.x.x.x.x') }}
    test:
      imports:
        - airflow.lineage
        - airflow.lineage.entities
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-webhdfs
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage('airflow-with-apache-webhdfs', max_pin='x.x.x.x.x.x') }}
    test:
      imports:
        - airflow
        - hdfs
        - airflow.hooks.webhdfs_hook
      commands:
        - pip check
      requires:
        - pip

about:
  home: http://airflow.apache.org
  license: Apache-2.0
  license_file: LICENSE
  summary: |
    Airflow is a platform to programmatically author, schedule and monitor
    workflows

  description: |
    Use airflow to author workflows as directed acyclic graphs (DAGs)
    of tasks. The airflow scheduler executes your tasks on an array of
    workers while following the specified dependencies. Rich command
    line utilities make performing complex surgeries on DAGs a snap.
    The rich user interface makes it easy to visualize pipelines
    running in production, monitor progress, and troubleshoot issues
    when needed.

    When workflows are defined as code, they become more maintainable,
    versionable, testable, and collaborative.

  doc_url: http://pythonhosted.org/airflow/profiling.html
  dev_url: https://github.com/apache/airflow

extra:
  recipe-maintainers:
    - sodre
    - halldc
    - xylar
