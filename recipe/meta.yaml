{% set name = "airflow" %}
{% set version = "1.10.0" %}
{% set sha256 = "cf4f67ca53d471db44d8b1620dbef22210299f5de55ce72a3b9981e7d6ae6636" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  fn: {{ name }}-{{ version }}.tar.gz
  url: https://github.com/apache/incubator-{{ name }}/archive/{{ version }}.tar.gz
  sha256: {{ sha256 }}

build:
  skip: True  # [win]
  number: 1

test:
  commands:
    - echo 'Keep lint happy'

outputs:
  - name: {{ name }}
    script: install_airflow.sh  # [unix]
    requirements:
      host:
        - python
        - pip
        - docutils >=0.14,<1.0
      run:
        - python
        - alembic >=0.8.3,<0.9
        - bleach ==2.1.2
        - configparser >=3.5.0,<3.6.0
        - croniter >=0.3.17,<0.4
        - dill >=0.2.2,<0.3
        - flask >=0.12.4,<0.13
        - flask-appbuilder >=1.11.1,<2.0.0
        - flask-admin ==1.4.1
        - flask-caching >=1.3.3,<1.4.0
        - flask-login ==0.2.11
        - flask-swagger ==0.2.13
        - flask-wtf >=0.14.2,<0.15
        - funcsigs ==1.0.0  # [py<33]
        - future >=0.16.0,<0.17
        - gitpython >=2.0.2
        - gunicorn >=19.4.0,<20.0
        - iso8601 >=0.1.12
        - jinja2 >=2.7.3,<2.9.0
        - lxml >=3.6.0,<4.0
        - markdown >=2.5.2,<3.0
        - pandas >=0.17.1,<1.0.0
        - pendulum ==1.4.4
        - psutil >=4.2.0,<5.0.0
        - pygments >=2.0.1,<3.0
        - python-daemon >=2.1.1,<2.2
        - python-dateutil >=2.3,<3
        - python-nvd3 ==0.15.0
        - requests >=2.5.1,<3
        - setproctitle >=1.1.8,<2
        - sqlalchemy >=1.1.15,<1.2.0
        - tabulate >=0.7.5,<0.8.0
        - tenacity ==4.8.0
        - thrift >=0.9.2
        - tzlocal >=1.4
        - unicodecsv >=0.14.1
        - werkzeug >=0.14.1,<0.15.0
        - zope.deprecation >=4.0,<5.0
    test:
      commands:
        - airflow initdb
      imports:
        - airflow
        - airflow.api
        - airflow.api.auth
        - airflow.api.auth.backend
        - airflow.api.client
        - airflow.api.common
        - airflow.api.common.experimental
        - airflow.bin
        - airflow.config_templates
        - airflow.contrib
        - airflow.contrib.auth
        - airflow.contrib.auth.backends
        - airflow.contrib.executors
        - airflow.contrib.hooks
        - airflow.contrib.kubernetes
        - airflow.contrib.kubernetes.kubernetes_request_factory
        - airflow.contrib.operators
        - airflow.contrib.sensors
        - airflow.contrib.task_runner
        - airflow.contrib.utils
        - airflow.dag
        - airflow.example_dags
        - airflow.example_dags.subdags
        - airflow.executors
        - airflow.hooks
        - airflow.lineage
        - airflow.lineage.backend
        - airflow.macros
        - airflow.migrations
        - airflow.migrations.versions
        - airflow.operators
        - airflow.security
        - airflow.sensors
        - airflow.task
        - airflow.task.task_runner
        - airflow.ti_deps
        - airflow.ti_deps.deps
        - airflow.utils
        - airflow.utils.log
        - airflow.www
        - airflow.www.api
        - airflow.www.api.experimental
        - airflow.www_rbac
        - airflow.www_rbac.api
        - airflow.www_rbac.api.experimental


  - name: {{ name }}-with-async
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - greenlet >=0.4.9
        - eventlet >=0.9.7
        - gevent >=0.13

  # - name: {{ name }}-with-atlas
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - atlasclient >=0.1.2
  #   test:
  #     imports:
  #       - airflow.lineage.backend.atlas

  - name: {{ name }}-with-azure_blob_storage
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - azure-storage >=0.34.0

  # we are missing azure-mgmt-datalake-store and azure-datalake-store
  # - name: {{ name }}-with-azure_data_lake
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - azure-mgmt-resource ==1.2.2
  #       - azure-mgmt-datalake-store ==0.4.0
  #       - azure-datalake-store ==0.0.19

  - name: {{ name }}-with-cassandra
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cassandra-driver >=3.13.0

  - name: {{ name }}-with-celery
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - celery >=4.1.1,<4.2.0
        - flower >=0.7.3,<1.0

  - name: {{ name }}-with-cgroups
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cgroupspy >=0.1.4

  - name: {{ name }}-with-cloudant
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cloudant >=0.5.9,<2.0

  - name: {{ name }}-with-crypto
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cryptography >=0.9.3

  - name: {{ name }}-with-dask
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - distributed >=1.17.1,<2

  - name: {{ name }}-with-databricks
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - requests >=2.5.1,<3

  - name: {{ name }}-with-datadog
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - datadog >=0.14.0

  - name: {{ name }}-with-docker
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - docker-py >=2.0.0

  - name: {{ name }}-with-druid
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pydruid >=0.4.1

  - name: {{ name }}-with-elasticsearch
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - elasticsearch >=5.0.0,<6.0.0
        - elasticsearch-dsl >=5.0.0,<6.0.0

  - name: {{ name }}-with-emr
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - boto3 >=1.0.0

  # we are missing google-cloud-container
  # - name: {{ name }}-with-gcp_api
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - httplib2 >=0.9.2
  #       - google-api-python-client >=1.6.0,<2.0.0dev
  #       - google-auth >=1.0.0,<2.0.0dev
  #       - google-auth-httplib2 >=0.0.1
  #       - google-cloud-container >=0.1.1
  #       - pyopenssl
  #       - pandas-gbq

  - name: {{ name }}-with-github_enterprise
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - flask-oauthlib >=0.9.1

  - name: {{ name }}-with-hdfs
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - snakebite >=2.7.8

  # - name: {{ name }}-with-hive
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - hmsclient >=0.1.0
  #       - pyhive >=0.6.0

  - name: {{ name }}-with-jdbc
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - jaydebeapi >=1.1.1

  - name: {{ name }}-with-jenkins
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-jenkins >=0.4.15

  - name: {{ name }}-with-jira
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - jira >=1.0.7

  # We are missing python-krbv and apple/kerberos
  #- name: {{ name }}-with-kerberos
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - pykerberos >=1.1.13
  #      - requests-kerberos >=0.10.0
  #      - thrift_sasl >=0.2.0
  #      - sasl
  #      - python-krbv
  #      - kerberos >=1.2.5

  - name: {{ name }}-with-kubernetes
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-kubernetes >=3.0.0
        - cryptography >=2.0.0

  - name: {{ name }}-with-ldap
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - {{ name }}
        - ldap3 >=0.9.9.1

  - name: {{ name }}-with-mongo
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pymongo >=3.6.0

  - name: {{ name }}-with-mssql
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - {{ name }}
        - pymssql >=2.1.1

  #- name: {{ name }}-with-mysql
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - {{ name }}
  #      - mysqlclient >=1.3.6

  #- name: {{ name }}-with-oracle
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - {{ name }}
  #      - cx_oracle>=5.1.2

  - name: {{ name }}-with-password
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - bcrypt >=2.0.0
        - flask-bcrypt >=0.7.1

  # - name: {{ name }}-with-pinot
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - pinotdb >=0.1.1

  - name: {{ name }}-with-postgres
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - psycopg2 >=2.7.4

  - name: {{ name }}-with-qds
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - qds-sdk>=1.9.6

  - name: {{ name }}-with-rabbitmq
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - librabbitmq >=1.6.1

  - name: {{ name }}-with-redis
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - redis-py >=2.10.5

  - name: {{ name }}-with-s3
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - boto3 >=1.7.0

  - name: {{ name }}-with-salesforce
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - simple-salesforce >=0.72

  - name: {{ name }}-with-samba
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pysmbclient >=0.1.3

  # - name: {{ name }}-with-segment
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - analytics-python >=1.2.9

  - name: {{ name }}-with-sendgrid
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - sendgrid >=5.2.0

  - name: {{ name }}-with-slack
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - slackclient >=1.0.0

  # - name: {{ name }}-with-snowflake
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - snowflake-connector-python >=1.5.2
  #       - snowflake-sqlalchemy >=1.1.0

  - name: {{ name }}-with-ssh
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - paramiko >=2.1.1
        - pysftp >=0.2.9

  - name: {{ name }}-with-statsd
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - statsd >=3.0.1,<4.0

  - name: {{ name }}-with-vertica
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - vertica-python >=0.5.1

  - name: {{ name }}-with-webhdfs
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-hdfs >=0.5.1

  - name: {{ name }}-with-winrm
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pywinrm ==0.2.2

  # - name: {{ name }}-with-zendesk
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - zdesk

about:
  home: http://airflow.apache.org
  license: Apache 2.0
  license_file: LICENSE
  summary: 'Airflow is a platform to programmatically author, schedule and monitor workflows'

  description: |
      Use airflow to author workflows as directed acyclic graphs (DAGs)
      of tasks. The airflow scheduler executes your tasks on an array of
      workers while following the specified dependencies. Rich command
      line utilities make performing complex surgeries on DAGs a snap.
      The rich user interface makes it easy to visualize pipelines
      running in production, monitor progress, and troubleshoot issues
      when needed.

      When workflows are defined as code, they become more maintainable,
      versionable, testable, and collaborative.

  doc_url: http://pythonhosted.org/airflow/profiling.html
  dev_url: https://github.com/apache/incubating-airflow

extra:
  recipe-maintainers:
    - sodre
    - halldc
